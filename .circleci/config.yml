# PHP CircleCI 2.0 configuration file
#
# Check https://circleci.com/docs/2.0/language-php/ for more details
#
# Silverstripe parallel workflow v1.0
# @see https://silverstripe.atlassian.net/wiki/spaces/DEV/pages/3047162082/CircleCI+Parallel+Workflow
#
version: 2.1

#
# GLOBAL PARAMETERS
# -----------------
#
parameters:
  image:
    type: string
    description: The image to use for the build. Details of what this image contains available at https://github.com/silverstripeltd/bespoke-ci-base/
    default: "ghcr.io/silverstripeltd/bespoke-ci-base:4.2.0"
  db_image:
    type: string
    description: The image to use for the database.
    default: "cimg/mysql:8.0"
  php_version:
    type: string
    description: The version of PHP to use.
    default: "8.3"
  create_test_deployment:
    description: Create a Silverstripe Cloud deployment for the QA/Test1 environment when code is merged to the `develop` branch, and approval is given via CircleCI.
    type: boolean
    default: false
  auto_deploy_to_test:
    description: Automatically deploy to the QA/Test1 environment after the deployment is created on Silverstripe Cloud.
    type: boolean
    default: false
  create_uat_deployment:
    description: Create a Silverstripe Cloud deployment for the UAT environment from a `release` or `hotfix` branch, and approval is given via CircleCI.
    type: boolean
    default: false
  auto_deploy_to_uat:
    description: Automatically deploy to the UAT environment after the deployment is created on Silverstripe Cloud.
    type: boolean
    default: false
  create_prod_deployment:
    description: Create a Silverstripe Cloud deployment for the Production environment when code is merged to the `main` branch, and approval is given via CircleCI.
    type: boolean
    default: false
  # auto_deploy_to_prod:
  #   description: Automatically deploy to the Production environment after the deployment is created on Silverstripe Cloud (not recommended)
  #   type: boolean
  #   default: false


#
# CONTAINER CONFIGURATION
# -----------------------
#
# Defines the two standard containers to execute the pipelines with
# - docker-executor: for building the application (default size; small)
# - docker-executor-with-mysql: for running the application (default size; small)
#
executors:
  #
  # The basic VM for running tasks
  #
  # @see https://circleci.com/docs/using-docker
  #
  docker-executor:
    parameters:
      size:
        description: "The resource class to use"
        default: "small"
        type: enum
        enum:
          - "small"   # 1 cpu, 2GB
          - "medium"  # 2 cpu, 4GB
          - "medium+" # 3 cpu, 6GB
          - "large"   # 4 cpu, 8GB
          - "xlarge"  # 8 cpu, 16GB
    docker:
      - image: << pipeline.parameters.image >>
        environment:
          DISPLAY: :99
          CHROME_BIN: /usr/bin/google-chrome-stable
          BASH_ENV: /home/vagrant/.bashrc
    resource_class: << parameters.size >>
    working_directory: /var/www/mysite/www
  #
  # The VM for running tasks which require a database
  #
  docker-executor-with-mysql:
    parameters:
      size:
        description: "The resource class to use"
        default: "small"
        type: enum
        enum: ["small", "medium", "medium+", "large", "xlarge"]
    docker:
      - image: << pipeline.parameters.image >>
        environment:
          DISPLAY: :99
          CHROME_BIN: /usr/bin/google-chrome-stable
          BASH_ENV: /home/vagrant/.bashrc
      - image: << pipeline.parameters.db_image >>
        environment:
          MYSQL_ROOT_PASSWORD: ubuntu
          MYSQL_DATABASE: circle_test
          MYSQL_HOST: 127.0.0.1
    resource_class: << parameters.size >>
    working_directory: /var/www/mysite/www

#
# REUSABLE COMMANDS
# -----------------
#
# Define the functions which trigger different tasks on the pipeline
#
commands:
  #
  # Start the processes we need to run in the background
  #
  background-services:
    description: Start Apache, Nginx and Xvfb
    steps:
      - run:
          name: Starting virtual framebuffer
          command: Xvfb :99 -screen 0 1280x1024x24
          background: true
      - run:
          name: Starting apache
          command: sudo service apache2 start
      - run:
          name: Starting nginx
          command: sudo service nginx start

  #
  # Install server-side and client-side dependencies
  # Using cached copies where possible
  #
  dependencies:
    description: Install dependencies
    steps:
      # Composer Cache + Installation
      - restore_cache:
          keys:
            - v1-composer-{{ checksum "composer.lock" }}
            # fallback to using the latest cache if no exact match is found
            - v1-composer-
      # If your project is running forks, you might need to add a Github Token in order to avoid rate limiting.
      # You should request your tech lead created/updates a Service Account for your project. A Token can then be
      # created for that Service Account and added to the Project Settings in CircleCI as an ENV Var
      # - run: composer config --global github-oauth.github.com $GITHUB_TOKEN
      # prefer source composer install to make test files available
      - run:
          name: Installing composer dependencies
          command: |
            composer install --prefer-dist --no-interaction
            # always expose: cached content is never exposed automatically
            composer vendor-expose
      # Save all dependencies to cache
      - save_cache:
          key: v1-composer-{{ checksum "composer.lock" }}
          paths:
            - vendor
            - resources

      # Yarn Cache + Installation
      - restore_cache:
          keys:
            - v1-yarn-deps-{{ checksum "yarn.lock" }}
            # fallback to using the latest cache if no exact match is found
            - v1-yarn-deps-
      - run:
          name: Installing yarn dependencies
          command: yarn install --frozen-lockfile
      - save_cache:
          paths:
            - ~/.cache
          key: v1-yarn-deps-{{ checksum "yarn.lock" }}

  #
  # Set the correct PHP version, as defined in the pipeline parameters
  #
  php-switch:
    description: Switch to the correct PHP version
    steps:
      - run:
          name: Setting PHP version to << pipeline.parameters.php_version >>
          command: php-switch << pipeline.parameters.php_version >>

  #
  # Install the node version required in `.nvmrc` and set as the default
  # Also install yarn, so we can add/update dependencies, build the project
  #
  install-node:
    description: Install/Update node.js
    steps:
      - run:
          name: Installing node.js
          command: |
            nvm install $(cat .nvmrc)
            nvm alias default $(cat .nvmrc)
      - run:
          name: Installing yarn
          command: npm install --global yarn

  #
  # Set the projects environment variables, specific to CircleCI execution
  #
  env-vars:
    description: Set environment variables
    steps:
      - run:
          name: Setting environment variables
          command: mv .circleci/.env.circleci .env

  #
  # Check that required environment variables are set
  # accepts an comma seperated array of environment variables names
  #
  check_env_vars:
    description: Check that required environment variables are set
    parameters:
      service:
        description: The service to check environment variables for
        type: string
      env_vars:
        description: CSV of environment variable names to check
        type: string
    steps:
      - run:
          name: Checking environment variables for << parameters.service >>
          command: |
            # Split env_vars string into an array
            env_vars_array=($(echo << parameters.env_vars >> | tr "," "\n"))
            for env_var in "${env_vars_array[@]}"
            do
              # Check if the environment variable is set and not empty
              if [ -z "${!env_var}" ]; then
                echo "Environment variable $env_var is not set or is empty."
                exit 1
              fi
            done

  #
  # Check that environment variables match a given pattern
  # accepts an comma seperated array of environment variables names and regex patterns
  # e.g. "DB_HOST=^localhost$,DB_PORT=^\d+$"
  #
  validate_env_vars:
    description: Check environment variables match a given pattern
    parameters:
      service:
        description: The service to check environment variable patterns for
        type: string
      env_vars_regex:
        description: CSV of environment variable names and regex patterns to check
        type: string
    steps:
      - run:
          name: Validate environment variable values for << parameters.service >>
          command: |
            # Split env_vars string into an array
            env_vars_regex_array=($(echo << parameters.env_vars_regex >> | tr "," "\n"))
            for env_var_regex in "${env_vars_regex_array[@]}"
            do
              # Split the env_var_regex string into a variable name and regex pattern
              env_var="${env_var_regex%=*}"
              regex="${env_var_regex#*=}"
              # Test the environment variable matches the regex
              if ! [[ "${!env_var}" =~ $regex ]]; then
                echo "Environment variable $env_var value does not match the expected pattern: $regex."
                exit 1
              fi
            done

  #
  # Make sure the correct permissions are set
  #
  setup-permissions:
    steps:
      - run:
          name: Setting permissions
          command: |
            chown -R vagrant:vagrant /var/www/mysite/www
            chmod g+s /var/www/mysite/www/public

  #
  # Build the development assets
  #
  yarn-dev:
    description: Build dev files for coverage instrumentation
    steps:
      - run:
          name: Building development assets
          command: yarn dev

  #
  # Populate the database
  # v3.0.1
  #
  # This can be set to always populate from fixtures, or to use the
  # cached population with a stored mysql dump from the previous time.
  #
  populate:
    description: Add data to the database for testing
    parameters:
      cache:
        description: Use cached population if available (beta)
        type: boolean
        default: false
      pre:
        description: If using cached population, this is a pre-populate flag to generate the sql used in later steps
        type: boolean
        default: false
      ttl:
        description: The maximum time to hold the cache for in days, circle ci max is 15 days
        type: integer
        default: 15
    steps:
      - when:
          condition: << parameters.cache >>
          steps:
          - run:
              name: Generating populate checksum
              command: |
                git hash-object composer.lock app/_config/populate.yml app/populate/fixtures/*.yml > populate-hash
                x=$(date "+%s"); y=$(($x - ($x % (<< parameters.ttl >> * 24 * 60 * 60)))); echo "$(date -d"@$y")" >> populate-hash
          - restore_cache:
              keys:
                - v1-populate-{{ checksum "populate-hash" }}
          - run:
              name: Populating database
              command: |
                source .env
                if [[ << parameters.cache >> = true && -e ~/.database/db.sql && << parameters.pre >> = false ]]; then
                  echo "Using cached database sql file"
                  mysql -h ${SS_DATABASE_SERVER} -u ${SS_DATABASE_USERNAME} -p${SS_DATABASE_PASSWORD} ${SS_DATABASE_NAME} < ~/.database/db.sql
                  # move the cached (minimal) populate to replace the one in the repo to handle file population
                  mv ./.circleci/cached-populate.yml ./app/_config/populate.yml
                  sudo -u vagrant vendor/bin/sake dev/tasks/PopulateTask flush=1
                elif [[ ! -e ~/.database/db.sql ]]; then
                  echo "Populating the database from the fixtures"
                  sudo -u vagrant vendor/bin/sake dev/tasks/PopulateTask flush=1
                  # take a dump of the database for next time
                  mkdir ~/.database
                  echo "[mysqldump]" >> ~/.database/mysqlpassword.cnf
                  echo 'password="ubuntu"' >> ~/.database/mysqlpassword.cnf
                  mysqldump --defaults-file=~/.database/mysqlpassword.cnf -h ${SS_DATABASE_SERVER} -u ${SS_DATABASE_USERNAME} ${SS_DATABASE_NAME} > ~/.database/db.sql
                else
                  echo "Database sql already exists and pre-population is enabled (<< parameters.pre >>)"
                fi
          - save_cache:
              paths:
                - ~/.database/
              key: v1-populate-{{ checksum "populate-hash" }}
      - unless:
          condition: << parameters.cache >>
          steps:
            - run:
                name: Populating database from fixtures
                command: |
                  sudo -u vagrant vendor/bin/sake dev/tasks/PopulateTask flush=1

  #
  # Build the database structure and graphql cache
  #
  dev-build:
    description: Build the database with dev/build task
    steps:
      - run:
          name: Building database
          command: sudo -u vagrant vendor/bin/sake dev/build flush=1

  #
  # Check the code linting for Script, Styles and Code
  #
  silverstripe-standards:
    description: JS/SCSS/PHP Linting
    steps:
      - run:
          name: Checking against Silverstripe standards
          command: composer silverstripe-standards

  #
  # Run the PHP unit and functional tests in phpunit
  # v3.0.0
  #
  # Allows for optional generation of code coverage,
  # and splitting by timing for use in parallelisation
  #
  php-tests:
    description: phpunit tests
    parameters:
      coverage:
        type: boolean
        default: true
      pcov:
        type: boolean
        default: false
    steps:
      - run:
          name: Running phpunit tests
          command: |
            if << parameters.pcov >>;
            then
              phpdismod xdebug
            fi
            PHPUNITARGS=""
            if << parameters.coverage >>;
            then
              if << parameters.pcov >>;
              then
                # enable the line below if you are requiring private repos (e.g. silverstripeltd/elasticsearchapp)
                # see https://docs.github.com/en/github/authenticating-to-github/keeping-your-account-and-data-secure/creating-a-personal-access-token
                # composer config http-basic.github.com $SERVICE_ACCOUNT_USERNAME $SERVICE_ACCOUNT_GITHUB_API_TOKEN
                phpenmod -v << pipeline.parameters.php_version >> pcov
                COMPOSER_MEMORY_LIMIT=-1 composer require pcov/clobber --no-plugins
                vendor/bin/pcov clobber
              fi
              PHPUNITARGS=" --coverage-html coverage/php  --coverage-clover coverage/php/clover.xml --log-junit reports/php/junit.xml"
            fi
            TESTFILES=$(circleci tests glob "/var/www/mysite/www/app/tests/**/*Test.php" | circleci tests split --split-by=timings --index=$CIRCLE_NODE_INDEX | sed 's|/var/www/html/||' | sed 's/^/<file>/g' | sed 's|$|</file>|g' )
            TESTFILES="<testsuite name='PARALLEL'>""$TESTFILES""</testsuite></testsuites>"
            TESTFILES=$(echo $TESTFILES | sed -e 's/[\/&]/\\&/g')
            sed "s/<\/testsuites>/$TESTFILES/" phpunit.xml > phpunitparallel.xml
            cat phpunitparallel.xml
            vendor/bin/phpunit -d memory_limit=512M $PHPUNITARGS -c phpunitparallel.xml --testsuite "PARALLEL"

  #
  # Run the JS unit tests in jest
  #
  js-tests:
    description: JS/Vue (jest) Tests
    steps:
      - run:
          name: Running JS tests
          command: yarn test:app:ci
          environment:
            JEST_JUNIT_OUTPUT_DIR: ./reports/jest/

  #
  # Run the integration tests in Cypress
  # v2.0.0
  #
  # Allows for test splitting by timing
  # when used with parallelisation
  #
  e2e-tests:
    description: JS E2E (cypress) tests
    steps:
      # Restore the Cypress binary from cache
      - restore_cache:
          keys:
            - v1-yarn-deps-{{ checksum "yarn.lock" }}
      - run:
          name: Running e2e tests
          command: |
            TESTFILES=$(find ./cypress/e2e -name "*.feature" -type f -printf '%p\n' | circleci tests split --split-by=timings --index=$CIRCLE_NODE_INDEX --timings-type=filename | sed -z 's|\n|,|g;s|,$|\n|')
            yarn test:e2e --headless --spec $TESTFILES
            # add the relative file path to the testsuite with the timings
            # this allows circleci to use the split-by=timings function properly
            find ./reports/cypress/ -type f -name 'junit.*.xml' -exec sh -c 'sed -i "s@name=\"Root@file=\"$(sed -n "s@.*file=\"\([^\"]*\).*@\1@p" {} | grep -m1 "")\" name=\"Root@g" {}' \;

  #
  # Run the lighthouse tests
  #
  # Checking
  # - performance
  # - accessibility
  # - best practice
  # - seo
  #
  # @see https://lighthouse-silverstripe.herokuapp.com/
  # basic auth credentials in Lastpass
  #
  # Requires setup and $LHCI_BASIC_AUTH_PASSWORD variation set in CircleCI
  # @see https://silverstripe.atlassian.net/wiki/spaces/DEV/pages/1626013805/How+to+setup+CircleCI+for+Project+Skeleton#Enabling-Lighthouse-checks
  #
  lighthouse-checks:
    description: Lighthouse checks
    steps:
      - check_env_vars:
          service: Lighthouse
          env_vars: LHCI_BASIC_AUTH_PASSWORD
      - run:
          name: Checking with Lighthouse
          command: |
            yarn build
            npm install -g @lhci/cli@0.8.x
            lhci autorun --upload.basicAuth.username=silverstripe --upload.basicAuth.password=${LHCI_BASIC_AUTH_PASSWORD}

  #
  # Send the coverage reports to codecov.io
  #
  # Requires $CODECOV_TOKEN variable set in CircleCI
  #
  # CODECOV_TOKEN
  # - Creation:
  #   a) Login to GitHub as a user with admin access to the repo (PD/PL/etc)
  #   b) Login to CodeCov.io via GitHub OAuth
  #   c) https://app.codecov.io/gh/silverstripeltd
  #   d) Find (or add) the repository that you want tracked. You might need to allow permissions:
  #      - https://github.com/organizations/silverstripeltd/settings/installations/17904772
  #      - (If that link stops working: Github SS Ltd > Settings > Github Apps > Codecov
  #      - Update the list in "Only selected repositories" to include your repo
  #   d) Generate token: CODECOV_TOKEN
  # - Set token:
  #   a) https://circleci.com/gh/$REPO_NAME/environment-variables
  #   b) Name = CODECOV_TOKEN, Token = Generated from step above
  #
  codecov:
    description: Report coverage
    steps:
      - check_env_vars:
          service: Codecov
          env_vars: CODECOV_TOKEN
      - run:
          name: Sending coverage to codecov.io
          command: |
            curl -s https://codecov.io/bash > codecov;
            VERSION=$(grep 'VERSION=\".*\"' codecov | cut -d'"' -f2);
            shasum -a 512 -c  <(curl -s https://raw.githubusercontent.com/codecov/codecov-bash/${VERSION}/SHA512SUM | grep codecov);
            bash <(cat codecov) || echo "Codecov submission failed, check https://status.codecov.io"

  #
  # PACKAGE DEPLOYMENT COMMANDS
  # ---------------------------
  #
  # SERVICE_ACCOUNT_EMAIL
  # - Creation (should be done by SA/PD/TD):
  #   a) Setup in Github - see: https://silverstripe.atlassian.net/wiki/spaces/IS/pages/1270186089/Github#Service-Accounts
  #   b) Create a new account in Silverstripe Cloud using the Service Account email details
  #   c) Add account as a 'Team Member' on the stack
  #
  # ENVIRONMENT VARIABLES - required to be added to CircleCI project before continuing
  # - $REPO_NAME: e.g. "silverstripeltd/<project-name>"
  # - $SERVICE_ACCOUNT_EMAIL: e.g. "serviceaccounts+<project-name>@silverstripe.com"
  # - $STACK_NAME: e.g. "helpport" (from "silverstripe.cloud/naut/project/<stack-name>")
  #
  # Notes to set API tokens if account is ever disabled/access revoked
  #
  # CLOUD_USER_API_TOKEN
  # - Creation:
  #   a) Login to Silverstripe Cloud as a user with access to the Cloud stack
  #   b) Click the 'Generate API Token' button from https://silverstripe.cloud/naut/profile
  # - Set here: https://circleci.com/gh/$REPO_NAME/environment-variables
  #   a) Name = CLOUD_USER_API_TOKEN
  #   b) Token = Generated from Environment Variables
  #
  # CIRCLE_CI_USER_API_TOKEN
  # - Creation:
  #   a) Login to GitHub as a user with access to the code repo
  #   b) Login to CircleCI via GitHub OAuth
  #   c) https://circleci.com/account/api
  # - Set here: https://circleci.com/gh/$REPO_NAME/environment-variables
  #   a) Name = CIRCLE_CI_USER_API_TOKEN
  #   b) Token = Generated from Environment Variables
  #
  # grep at the end to fail if not a successful call to the API
  #
  # These can be removed if you are not using package deployments,
  # leaving them here won't create any issues though.
  #
  deploy_to_env:
    description: Get public location of artifacts from this build and run a deployment to a given environment
    parameters:
      env:
        type: string
      bypass:
        type: boolean
        default: true
      bypass_and_start:
        type: boolean
        default: false
    steps:
      - check_env_vars:
          service: Package deployment
          env_vars: REPO_NAME,SERVICE_ACCOUNT_EMAIL,STACK_NAME,CLOUD_USER_API_TOKEN,CIRCLE_CI_USER_API_TOKEN
      - validate_env_vars:
          service: Package deployment
          env_vars_regex: REPO_NAME=^silverstripeltd/.*,SERVICE_ACCOUNT_EMAIL=^serviceaccounts\+.*@silverstripe.com,STACK_NAME=^[a-z0-9-]+$
      - run:
          name: Sending artifacts to Silverstripe Cloud
          command: |
            curl -L https://circleci.com/api/v1.1/project/github/$REPO_NAME/$(cat /tmp/buildnum/num.txt)/artifacts -H "Circle-Token: $CIRCLE_CI_USER_API_TOKEN" | grep -o 'https://[^"]*' > artifacts.txt
            echo "{ \"ref\": \"$(cat artifacts.txt)?circle-token=$CIRCLE_CI_USER_API_TOKEN\", \"ref_type\": \"package\", \"title\": \"[CI] $CIRCLE_BRANCH\", \"summary\": \"Automatically deployed from CircleCI \\nRepository: $CIRCLE_REPOSITORY_URL \\nCode: $(cat artifacts.txt) \\nSHA_COMMIT_MESSAGE: $(cat /tmp/gitlog/message.txt) \", \"bypass\": << parameters.bypass >>, \"bypass_and_start\": << parameters.bypass_and_start >> }" > data.json
            curl -X POST -u $SERVICE_ACCOUNT_EMAIL:$CLOUD_USER_API_TOKEN https://silverstripe.cloud/naut/project/$STACK_NAME/environment/<< parameters.env >>/deploys -H 'Content-Type: application/json' -H 'Accept: application/json' --data @data.json |& tee results.json
            grep '"status_code": 201' results.json

  #
  # Package the codebase for deployment, with either development assets or production
  #
  # Includes options to allow the static storybook to also be published
  #
  package:
    description: Package the codebase
    parameters:
      include_storybook:
        type: boolean
        default: true
      compile_for_prod:
        type: boolean
        default: false
    steps:
      # Use correct php/node versions
      - php-switch
      - install-node
      - setup-permissions
      - run:
          name: Adding github as known host
          # This happens at 'checkout' in other jobs but we manually do it here as this job has no 'checkout' step
          command: mkdir ~/.ssh/ && ssh-keyscan -H github.com >> ~/.ssh/known_hosts
      - run:
          name: Storing git log details
          # save git log message to add to data.json for deployment later and ensure no double quotes to prevent valid json issues
          command: mkdir /tmp/gitlog && touch /tmp/gitlog/message.txt && git log --format=oneline -n 1 $CIRCLE_SHA1 | sed "s/\"/'/g" >> /tmp/gitlog/message.txt
      - run:
          name: Compressing built and tested code then store as an artifact
          # Remove dev dependencies and git dir
          # tar compress and store in easily findable location
          command: |
            << parameters.include_storybook >> && yarn storybook:build && mv storybook-static public/storybook
            << parameters.compile_for_prod >> && yarn build || yarn dev
            rm -rf vendor
            composer install --no-interaction --optimize-autoloader --prefer-dist --no-dev
            composer vendor-expose
            rm -rf .git
            rm -rf .nyc_output
            rm -rf node_modules
            rm -rf public/assets
            rm -rf themes/app/src
            rm -rf themes/app/tests
            rm -rf docs
            rm -rf coverage
            rm -rf cypress
            rm -rf .storybook
            rm -rf stories
            rm -rf .github
            rm -rf .circleci
            rm -f .env
            cd ..
            cp -rp www site
            mkdir /builds
            tar -zcf /builds/$CIRCLE_SHA1 site
      - run:
          name: Storing build information
          command: mkdir /tmp/buildnum && touch /tmp/buildnum/num.txt && echo $CIRCLE_BUILD_NUM >> /tmp/buildnum/num.txt

#
# PARALLEL PIPELINE JOBS
# -------------
#
# Define the specific commands to perform CI processes.
#
jobs:
  #
  # Build the application and lint
  #
  build:
    executor:
      name: docker-executor-with-mysql
      size: medium

    steps:
      - checkout

      # setup
      - php-switch
      - install-node
      - env-vars
      - background-services
      - dependencies
      - setup-permissions

      # linting
      - silverstripe-standards

      # build dev assets
      - yarn-dev

      # build the database
      - dev-build

      # populate the database, if using populate
      # this creates the sql file to be used for quick population in later steps
      # - populate:
      #     cache: true
      #     pre: true

      - persist_to_workspace:
          root: /var/
          paths:
            - www/mysite/www

      - store_artifacts:
          path: silverstripe.log

  #
  # Run the unit tests
  #
  unit_test:
    # Define the number of processors to use
    parallelism: 1
    executor: docker-executor-with-mysql

    steps:
      - attach_workspace:
          at: /var/

      # setup
      - php-switch
      - install-node
      - setup-permissions

      # Build the database
      - dev-build

      # run test suites
      - php-tests
      - js-tests

      # Send coverage reports
      - codecov

      # Store test results for use in CircleCI
      - store_test_results:
          path: reports

      - store_artifacts:
          path: silverstripe.log

  #
  # Run the integration tests
  #
  integration_test:
    # Define the number of processors to use
    parallelism: 1
    executor: docker-executor-with-mysql

    steps:
      - attach_workspace:
          at: /var/

      # Setup
      - php-switch
      - install-node
      - background-services
      - setup-permissions

      # Build the database
      - dev-build

      # populate the database, using the cache if available
      # - populate:
      #     cache: true

      # Run tests
      - e2e-tests

      # Send coverage reports
      - codecov

      # Store artifacts for later use
      - store_artifacts:
          path: cypress/screenshots

      - store_artifacts:
          path: cypress/videos

      - store_artifacts:
          path: silverstripe.log

      # Store test results for use in CircleCI
      - store_test_results:
          path: reports

  #
  # Run the lighthouse tests for
  # performance, accessibility, best practice and seo
  #
  lighthouse_test:
    executor: docker-executor-with-mysql

    steps:
      - attach_workspace:
          at: /var/

      # Setup
      - php-switch
      - install-node
      - background-services
      - setup-permissions

      # Build the database
      - dev-build

      # populate the database, using the cache if available
      # - populate:
      #     cache: true

      # Run tests
      - lighthouse-checks

# PACKAGE DEPLOYMENT WORKFLOW
# ---------------------------
# conditional functions below are enabled in the pipeline parameters [line 7]
# the functionality can be enabled if the client has agreed to use
# package deployments to Silverstripe Cloud environments

  #
  # Package the built and tested code as it will be deployed
  #
  package_app:
    working_directory: /var/www/mysite/www
    executor: docker-executor

    steps:
      - when:
          condition:
            or:
              - equal: [ true, << pipeline.parameters.create_uat_deployment >> ]
              - equal: [ true, << pipeline.parameters.create_prod_deployment >> ]
          steps:
            - attach_workspace:
                at: /var/

            - package:
                include_storybook: false
                compile_for_prod: true

            - persist_to_workspace:
                root: /tmp
                paths:
                  - buildnum
                  - gitlog

            - store_artifacts:
                # Directory on file system to store as artifact
                path: /builds
      - run:
          name: Done
          command: echo .

  #
  # Package the built and tested code with development helpers
  #
  package_app_for_test:
    working_directory: /var/www/mysite/www
    executor: docker-executor

    steps:
      - when:
          condition: << pipeline.parameters.create_test_deployment >>
          steps:
            - attach_workspace:
                at: /var/

            - package:
                include_storybook: true
                compile_for_prod: false

            - persist_to_workspace:
                root: /tmp
                paths:
                  - buildnum
                  - gitlog

            - store_artifacts:
                # Directory on file system to store as artifact
                path: /builds
      - run:
          name: Done
          command: echo .

  #
  # Deploy site to QC/Test1 environment, if available
  #
  deploy_to_test:
    working_directory: /tmp

    docker:
      - image: << pipeline.parameters.image >>

    steps:
      - when:
          condition: << pipeline.parameters.create_test_deployment >>
          steps:
            - attach_workspace:
                at: /tmp

            - deploy_to_env:
                env: test1
                bypass: false
                bypass_and_start: << pipeline.parameters.auto_deploy_to_test >>
      - run:
          name: Done
          command: echo .

  #
  # Deploy site to UAT
  #
  deploy_to_uat:
    working_directory: /tmp

    docker:
      - image: << pipeline.parameters.image >>

    steps:
      - when:
          condition: << pipeline.parameters.create_uat_deployment >>
          steps:
            - attach_workspace:
                at: /tmp

            - deploy_to_env:
                env: uat
                bypass: false
                bypass_and_start: << pipeline.parameters.auto_deploy_to_uat >>
      - run:
          name: Done
          command: echo .

  #
  # Prepare a deployment to the production environment
  #
  deploy_to_prod:
    working_directory: /tmp

    docker:
      - image: << pipeline.parameters.image >>

    steps:
      - when:
          condition: << pipeline.parameters.create_prod_deployment >>
          steps:
            - attach_workspace:
                at: /tmp

            # Queue up a manual deployment
            - deploy_to_env:
                env: prod
                bypass: false
                # bypass_and_start: << pipeline.parameters.auto_deploy_to_prod >>
      - run:
          name: Done
          command: echo .

#
# WORKFLOWS
# ---------
#
# Define the continuous integration model
#
# Branch masks can be added and removed as is applicable to the project
#
workflows:
  build_and_deploy:
    jobs:
      # Build the application
      - build

      # Run unit tests
      - unit_test:
          requires:
            - build

      # Run integration tests
      - integration_test:
          requires:
            - build

      # Run lighthouse tests
      - lighthouse_test:
          requires:
            - build

      # Wait for approval before continuing
      - hold_for_deployment:
          type: approval
          filters:
            branches:
              only:
                - develop
                - /release\/.*/
                - /hotfix\/.*/
                # You might want to add main back in. It's commented out below so that
                # the Skeleton repo itself does not have this step on our main branch
                # - main

      # Package the application for the test environment
      # including storybook
      - package_app_for_test:
          requires:
            - hold_for_deployment # remove this to deploy automatically
            - build
          filters:
            branches:
              only:
                - develop

      # Package the application for the production environment
      - package_app:
          requires:
            - hold_for_deployment
            - build
          filters:
            branches:
              only:
                - /release\/.*/
                - /hotfix\/.*/
                # Uncomment the line below to deploy from main. It's commented out
                # so that the Skeleton repo itself does not have this step on our main branch
                # - main

      # Deploy to the QC/Test1 environment, if available
      - deploy_to_test:
          requires:
            - package_app_for_test
            - unit_test
            - integration_test
          filters:
            branches:
              only:
                - develop

      # Deploy to the UAT environment
      - deploy_to_uat:
          requires:
            - package_app
            - unit_test
            - integration_test
          filters:
            branches:
              only:
                - /release\/.*/
                - /hotfix\/.*/

      # Prepare a deployment to the production environment
      # Uncomment the section below to deploy from main. It's commented out
      # so that the Skeleton repo itself does not have this step on our main branch
      # - deploy_to_prod:
      #     requires:
      #       - package_app
      #       - unit_test
      #       - integration_test
      #     filters:
      #       branches:
      #         only:
      #           - main
